{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f987f91e",
   "metadata": {},
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fccbeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import joblib\n",
    "import shap\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "ROOT_PATH = Path().resolve().parent\n",
    "sys.path.append(str(ROOT_PATH))\n",
    "\n",
    "from src.utils.config import (\n",
    "    SAVE_PATH,\n",
    "    label,\n",
    "    primary_metric\n",
    ")\n",
    "\n",
    "from src.utils.modeling import prepare_data\n",
    "from src.utils.evaluation import evaluate_pipeline, summarize_model_results\n",
    "\n",
    "# Load data\n",
    "data = joblib.load(SAVE_PATH / \"data.pkl\")\n",
    "\n",
    "X = data[\"X\"]\n",
    "X_train = data[\"X_train\"]\n",
    "y_train = data[\"y_train\"]\n",
    "X_test = data[\"X_test\"]\n",
    "y_test = data[\"y_test\"]\n",
    "\n",
    "# Bundle into one variable for evaluation\n",
    "data = [X, X_train, y_train, X_test, y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce52941",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c7afe1",
   "metadata": {},
   "source": [
    "### DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3307f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy_pipeline, dummy_data = evaluate_pipeline('dummy_classifier', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eef4ef",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae5c6c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic_pipeline, logistic_data = evaluate_pipeline('logistic_regression', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df153816",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baa8acad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest_pipeline, forest_data = evaluate_pipeline('random_forest', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854faf2a",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e028d9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 175 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n175 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 754, in fit_transform\n    result = self._fit_transform(X, y, _fit_transform_one)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 681, in _fit_transform\n    return Parallel(n_jobs=self.n_jobs)(\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n    return super().__call__(iterable_with_config)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 1986, in __call__\n    return output if self.return_generator else list(output)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 1914, in _get_sequential_output\n    res = func(*args, **kwargs)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n    return self.function(*args, **kwargs)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\category_encoders\\utils.py\", line 298, in fit\n    X, y = convert_inputs(X, y)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\category_encoders\\utils.py\", line 89, in convert_inputs\n    raise ValueError(msg)\nValueError: `X` and `y` both have indexes, but they do not match. If you are shuffling your input data on purpose (e.g. via permutation_test_score) use np arrays instead of data frames / series\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m light_pipeline, light_data \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlightgbm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\ML-Templates\\src\\utils\\evaluation.py:45\u001b[0m, in \u001b[0;36mevaluate_pipeline\u001b[1;34m(name, data)\u001b[0m\n\u001b[0;32m     42\u001b[0m         y_test \u001b[38;5;241m=\u001b[39m y_test\u001b[38;5;241m.\u001b[39mmap(label_mapping)\n\u001b[0;32m     44\u001b[0m has_test_labels \u001b[38;5;241m=\u001b[39m y_test \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misna(y_test)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m---> 45\u001b[0m pipe \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_test_labels:\n\u001b[0;32m     48\u001b[0m     y_preds, y_probs \u001b[38;5;241m=\u001b[39m predict_pipeline(pipe, X_test)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\ML-Templates\\src\\utils\\modeling.py:118\u001b[0m, in \u001b[0;36mtrain_pipeline\u001b[1;34m(name, X_train, y_train)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m search_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    116\u001b[0m     search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(pipe, param_distributions\u001b[38;5;241m=\u001b[39mparam_grid, n_iter\u001b[38;5;241m=\u001b[39mn_iter, cv\u001b[38;5;241m=\u001b[39mskf, scoring\u001b[38;5;241m=\u001b[39mprimary_metric, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 118\u001b[0m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m best_model \u001b[38;5;241m=\u001b[39m search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBest hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1809\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1808\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1809\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1810\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1811\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1812\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1813\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    870\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    873\u001b[0m     )\n\u001b[1;32m--> 875\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32mc:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m     )\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 175 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n175 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 754, in fit_transform\n    result = self._fit_transform(X, y, _fit_transform_one)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 681, in _fit_transform\n    return Parallel(n_jobs=self.n_jobs)(\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n    return super().__call__(iterable_with_config)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 1986, in __call__\n    return output if self.return_generator else list(output)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\", line 1914, in _get_sequential_output\n    res = func(*args, **kwargs)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n    return self.function(*args, **kwargs)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\category_encoders\\utils.py\", line 298, in fit\n    X, y = convert_inputs(X, y)\n  File \"c:\\Users\\rober\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\category_encoders\\utils.py\", line 89, in convert_inputs\n    raise ValueError(msg)\nValueError: `X` and `y` both have indexes, but they do not match. If you are shuffling your input data on purpose (e.g. via permutation_test_score) use np arrays instead of data frames / series\n"
     ]
    }
   ],
   "source": [
    "light_pipeline, light_data = evaluate_pipeline('lightgbm', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a79aef",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aead387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precomputed metric results from evaluation\n",
    "model_data = {\n",
    "    # 'dummy_classifier': dummy_data,\n",
    "    # 'logistic_regression': logistic_data,\n",
    "    # 'random_forest': forest_data,\n",
    "    'lightgbm': light_data\n",
    "}\n",
    "\n",
    "fitted_pipelines = {\n",
    "    # 'dummy_classifier': dummy_pipeline,\n",
    "    # 'logistic_regression': logistic_pipeline,\n",
    "    # 'random_forest': forest_pipeline,\n",
    "    'lightgbm': light_pipeline\n",
    "}\n",
    "\n",
    "metrics_to_display = {\n",
    "    'F1': '{:.2%}',\n",
    "    'Accuracy': '{:.2%}',\n",
    "    'Precision': '{:.2%}',\n",
    "    'Roc_auc': '{:.2%}'\n",
    "}\n",
    "metrics_to_display = {primary_metric.capitalize(): metrics_to_display[primary_metric.capitalize()], **{k: v for k, v in metrics_to_display.items() if k != primary_metric.capitalize()}}\n",
    "\n",
    "best_model, best_pipeline = summarize_model_results(\n",
    "    model_data,\n",
    "    primary_metric,\n",
    "    metrics_to_display,\n",
    "    fitted_pipelines\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1c18ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = X_train\n",
    "\n",
    "# Get predictions on training data\n",
    "y_train_pred = best_pipeline.predict(X_train)\n",
    "\n",
    "# Only get wrong predictions\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "wrong_mask = y_train_pred != y_train\n",
    "wrong_examples = X_train_preprocessed.loc[wrong_mask]\n",
    "\n",
    "label_map = {\n",
    "    0: f\"Not {label}\",\n",
    "    1: label.capitalize()\n",
    "}\n",
    "\n",
    "display = wrong_examples.copy()\n",
    "display['Actual'] = y_train[wrong_mask].values\n",
    "display['Predicted'] = y_train_pred[wrong_mask]\n",
    "\n",
    "display['Actual'] = display['Actual'].map(label_map)\n",
    "display['Predicted'] = display['Predicted'].map(label_map)\n",
    "\n",
    "# Show a few wrong examples\n",
    "display.sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbda5652",
   "metadata": {},
   "source": [
    "#### Model performance metrics\n",
    "Summarize the key evaluation metrics and what they say about the model's overall predictive power. Highlight any strengths or weaknesses revealed by these numbers\n",
    "\n",
    "#### Feature importance analysis\n",
    "Describe which features contribute most to the model's decisions. Include insights from feature importance scores, SHAP values, and more. Explain why certain features might be especially influential\n",
    "\n",
    "#### Overfitting/underfitting and generalization\n",
    "Discuss evidence of overfitting/underfitting, if any. Use training vs. validation scores, learning curves, or cross-validation results to support analysis. Explain how well the model is expected to perform on unseen data\n",
    "\n",
    "#### Comparison to baseline models\n",
    "Compare the model's performance to the basline models, Dummy and Logistic Regression. Highlight improvements and explain why this model is a better choice than those options\n",
    "\n",
    "#### Error analysis\n",
    "Common failure cases (e.g., certain classes, edge cases) and examples of misclassified instances\n",
    "\n",
    "#### Model deployment considerations\n",
    "Inference time and scalability. Will it work for real time predictions?\n",
    "\n",
    "#### Data quality and preprocessing impact\n",
    "Effect of missing data handling and impact of feature engineering\n",
    "\n",
    "#### Summary\n",
    "Brief summary containing the most important points from the above information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12ab9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_row_idx = wrong_examples.index[0]\n",
    "\n",
    "row = display.loc[wrong_row_idx]\n",
    "actual_value = row['Actual']\n",
    "predicted_value = row['Predicted']\n",
    "\n",
    "model = best_pipeline.named_steps['model']\n",
    "\n",
    "shap_input = X_train_preprocessed.loc[[wrong_row_idx]]\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer.shap_values(shap_input)\n",
    "shap_values_instance = shap_values[1] \n",
    "shap_values_instance = shap.Explanation(\n",
    "    values=shap_values_instance[0].flatten(),  # Flatten the values to 1D to match the shape\n",
    "    base_values=explainer.expected_value[1],  # Base value for the positive class\n",
    "    data=shap_input.values.flatten(),  # Flatten the input values to match the expected shape\n",
    "    feature_names=X_train_preprocessed.columns.tolist()\n",
    ")\n",
    "\n",
    "print(f\"\\nSHAP explanation: (Pred: {predicted_value}, Actual: {actual_value})\")\n",
    "\n",
    "shap.plots.waterfall(shap_values_instance,show=False)\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "# Add custom labels on the left and right side of the plot\n",
    "# Left label\n",
    "ax.annotate(f\"Not {label}\", xy=(0, -.1), xycoords='axes fraction', \n",
    "            horizontalalignment='left', verticalalignment='bottom', fontsize=12, color='black')\n",
    "\n",
    "# Right label\n",
    "ax.annotate(label.capitalize(), xy=(1, -.1), xycoords='axes fraction', \n",
    "            horizontalalignment='right', verticalalignment='bottom', fontsize=12, color='black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f630abeb",
   "metadata": {},
   "source": [
    "Analyze what went wrong and why"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae5cdfd",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "#### Key insights\n",
    "\n",
    "#### Limitations and possible improvements\n",
    "\n",
    "#### Business implications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
