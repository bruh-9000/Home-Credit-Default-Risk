{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b7a56f6",
   "metadata": {},
   "source": [
    "# Project Overview\n",
    "\n",
    "#### Problem Statement\n",
    "Briefly describe the prediction task and why it matters for the business or users.\n",
    "\n",
    "#### Dataset Description\n",
    "Describe the dataset size, source, and feature types (numerical, categorical, text, etc.).\n",
    "\n",
    "#### Target Variable and Eval Metrics\n",
    "Define the target variable clearly. Specify the primary evaluation metric(s) and why they are appropriate for the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3771859c",
   "metadata": {},
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54b6d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rober\\Documents\\GitHub\\ML-Templates\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sys\n",
    "import yaml\n",
    "import joblib\n",
    "\n",
    "ROOT_PATH = Path().resolve().parent\n",
    "sys.path.append(str(ROOT_PATH))\n",
    "\n",
    "from src.utils.config import (\n",
    "    SAVE_PATH,\n",
    "    CONFIG_PATH\n",
    ")\n",
    "\n",
    "with open(CONFIG_PATH, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# file_path = config[\"general\"][\"file_path\"]\n",
    "\n",
    "from src.utils.preprocessing import prepare_train_test_split, dedup\n",
    "\n",
    "from features import add_custom_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a65bad",
   "metadata": {},
   "source": [
    "# Load and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f41694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_file_path = config[\"general\"][\"main_file_path\"]\n",
    "bureau_file_path = config[\"general\"][\"bureau_file_path\"]\n",
    "bureaubal_file_path = config[\"general\"][\"bureaubal_file_path\"]\n",
    "prevapp_file_path = config[\"general\"][\"prevapp_file_path\"]\n",
    "\n",
    "# Load datasets\n",
    "main_df = pd.read_csv(main_file_path)\n",
    "bureau_df = pd.read_csv(bureau_file_path)\n",
    "bureau_balance_df = pd.read_csv(bureaubal_file_path)\n",
    "previous_application_df = pd.read_csv(prevapp_file_path)\n",
    "\n",
    "main_df = add_custom_features(main_df, bureau_df, bureau_balance_df, previous_application_df)\n",
    "\n",
    "# Deduplicate\n",
    "main_df = dedup(main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8786f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\rober\\\\Documents\\\\GitHub\\\\ML-Templates\\\\saved\\\\data.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, X_train, X_test, y_train, y_test = prepare_train_test_split(main_df)\n",
    "\n",
    "# Save the datasets for further use\n",
    "joblib.dump({\n",
    "    \"X\": X,\n",
    "    \"y\": y,\n",
    "    \"X_train\": X_train,\n",
    "    \"X_test\": X_test,\n",
    "    \"y_train\": y_train,\n",
    "    \"y_test\": y_test\n",
    "}, SAVE_PATH / \"data.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
