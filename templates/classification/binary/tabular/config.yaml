general:
  file_one_path: ../data/train.csv # train or main
  file_two_path: ../data/test.csv # test or null
  label: Label
  primary_metric: accuracy
  threshold: .5
  cv_splits: 5
  resampling_type: none # under, over, none
  resampling_strategy: .5
  drop_or_keep: keep # drop is blacklist, keep is whitelist

preprocessing:
  drop_features: []
  value_mappings: {}
  type_coercion: {}
  money_cols: [] # Columns to convert from money to int. Ex. '$1.00' to 1.00
  missing_handling: {} # drop, mean, median, mode, prior, or a specific value

encoding:
  numerical_scale_cols: []
  onehot_cols: []
  freq_cols: []
  target_cols: []
  ordinal_cols: []
  binned_cols: []
  hash_cols: []

model_configs:
  dummy_classifier:
    search_type: null
    baseline: true
    param_grid: {}

  logistic_regression:
    search_type: grid
    baseline: true
    param_grid:
      model__C: [0.01, 0.1]  # Inverse of regularization strength
      model__penalty: [l2]  # Which loss type is applied
      model__solver: [lbfgs]  # Algorithm used for optimization

  random_forest:
    search_type: random
    baseline: false
    n_iter: 75
    param_grid:
      model__max_depth: [5, 6, 8, 10, null]  # Maximum node depth each tree can have
      model__min_samples_split: [10, 50, 0.01, 0.02]  # Min samples to split a node
      model__min_samples_leaf: [4, 8, 10, 20]  # Min samples per leaf node
      model__max_leaf_nodes: [20, 40, null]  # Max leaf nodes per tree
      model__n_estimators: [50, 100, 150]  # Number of trees in the forest
      model__max_samples: [0.15, 0.2]  # Percent of samples per tree
      model__max_features: [sqrt]  # Max features considered per split
      model__criterion: [gini]  # Split criterion
      model__class_weight: [balanced]  # Weight adjustment for class imbalance

  lightgbm:
    search_type: random
    baseline: false
    n_iter: 75
    param_grid:
      model__max_depth: [3, 4, 6, 8, -1]  # Maximum node depth each tree can have
      model__n_estimators: [50, 100, 200, 350, 500]  # Number of boosting rounds
      model__learning_rate: [0.01, 0.03, 0.05]  # Shrinks the contribution of each tree
      model__num_leaves: [20, 30, 50, 70]  # Maximum leaves in one tree
      model__min_child_samples: [20, 50, 100]  # Min samples per leaf node
      model__min_split_gain: [0.1, 0.5, 1]  # Min gain required to split
      model__subsample: [0.6, 0.8]  # Percent of samples per tree
      model__colsample_bytree: [0.6, 0.8, 1]  # Fraction of features per tree
      model__reg_alpha: [0.1, 1]  # L1 regularization
      model__reg_lambda: [0.5, 1, 2, 3, 5, 10]  # L2 regularization
      model__class_weight: [none, balanced]  # Weight adjustment for class imbalance